{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9201bdce650c412cbdf35776d3658588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df0ded98c0f244f29d7d3c89a8c24a3b",
              "IPY_MODEL_5d112a12624a4ffaa2b01aee31ef2c65",
              "IPY_MODEL_039c6ad0e769410db2ab65abfbed21b6"
            ],
            "layout": "IPY_MODEL_ae94d4e9966441abbce82326a2485fb9"
          }
        },
        "df0ded98c0f244f29d7d3c89a8c24a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaec53d563f1471c8804b99f010648bd",
            "placeholder": "​",
            "style": "IPY_MODEL_7c2510a0aa194575963c63572df6e9a7",
            "value": "Map: 100%"
          }
        },
        "5d112a12624a4ffaa2b01aee31ef2c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee153541b27b47b7b44995f4f1c5fe86",
            "max": 3270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e57b5f1267f4d07800bff3dcd9e94eb",
            "value": 3270
          }
        },
        "039c6ad0e769410db2ab65abfbed21b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b527b13061424a16aee1a0cc8adb5ced",
            "placeholder": "​",
            "style": "IPY_MODEL_4f60072f012b4f8b926dc07d20eb9d1c",
            "value": " 3270/3270 [12:07&lt;00:00,  4.73 examples/s]"
          }
        },
        "ae94d4e9966441abbce82326a2485fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaec53d563f1471c8804b99f010648bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c2510a0aa194575963c63572df6e9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee153541b27b47b7b44995f4f1c5fe86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e57b5f1267f4d07800bff3dcd9e94eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b527b13061424a16aee1a0cc8adb5ced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f60072f012b4f8b926dc07d20eb9d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "l-OmQD2TH8O9"
      },
      "outputs": [],
      "source": [
        "!pip -q install transformers datasets peft accelerate adapter-transformers bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"boolq\")"
      ],
      "metadata": {
        "id": "zSzs5--7FQ5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_example(example):\n",
        "    question = example['question']\n",
        "    passage = example['passage']\n",
        "    answer = 'Yes' if example['answer'] else 'No'\n",
        "    prompt = f\"Question: {question}\\nPassage: {passage}\\nAnswer:\"\n",
        "    return {'input_text': prompt, 'target_text': answer}\n",
        "formatted_dataset = dataset.map(format_example, remove_columns=dataset['train'].column_names)"
      ],
      "metadata": {
        "id": "6OU6RKDrFeEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# tokenizer = LlamaTokenizer.from_pretrained('meta-llama/Llama-2-7b-hf')\n",
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    inputs = [f\"{input_text} {target_text}\" for input_text, target_text in zip(examples['input_text'], examples['target_text'])]\n",
        "\n",
        "    # Tokenize the combined text and return PyTorch tensors\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt',  # Ensure tensors are returned\n",
        "    )\n",
        "\n",
        "    # Create labels by cloning the input IDs\n",
        "    labels = model_inputs['input_ids'].clone()\n",
        "\n",
        "    # Determine the length of the input_text for each example\n",
        "    input_lengths = []\n",
        "    for input_text in examples['input_text']:\n",
        "        input_ids = tokenizer(\n",
        "            input_text,\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            add_special_tokens=False,  # Do not add special tokens here\n",
        "        )['input_ids']\n",
        "        input_lengths.append(len(input_ids))\n",
        "\n",
        "    # Mask the labels for the input_text portion\n",
        "    for i, input_length in enumerate(input_lengths):\n",
        "        labels[i, :input_length] = -100  # Use -100 to ignore the input tokens\n",
        "\n",
        "    model_inputs['labels'] = labels\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = formatted_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=formatted_dataset['train'].column_names,\n",
        ")"
      ],
      "metadata": {
        "id": "5N7y9nSaFr5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,  # We are not using masked language modeling\n",
        ")"
      ],
      "metadata": {
        "id": "zP-ULfLKTbEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = LlamaForCausalLM.from_pretrained('meta-llama/Llama-2-7b-hf', load_in_8bit=True, device_map='auto')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    # target_modules=['q_proj', 'v_proj'],\n",
        "    lora_dropout=0.1,\n",
        "    bias='none',\n",
        "    task_type='CAUSAL_LM'\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJoSF7AHGIGN",
        "outputId": "9a5a0889-3c92-4ccf-ba7e-c0f75db77e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# Set the pad_token to the eos_token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Update model's config\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=100,\n",
        "    # evaluation_strategy='steps',\n",
        "    # eval_steps=1000,\n",
        "    save_steps=3000,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=1000,\n",
        "    learning_rate=1e-4,\n",
        "    report_to='none',\n",
        ")\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "9HjKHsxpGWHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "bh0XGBoQGlV4",
        "outputId": "70414caf-9d6f-4eaa-baa6-79472497da92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2950' max='2950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2950/2950 1:25:54, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.093700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.983400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2950, training_loss=3.016124122748941, metrics={'train_runtime': 5156.7614, 'train_samples_per_second': 9.14, 'train_steps_per_second': 0.572, 'total_flos': 1.240140568854528e+16, 'train_loss': 3.016124122748941, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the validation split\n",
        "dataset = load_dataset(\"boolq\", split='validation')\n",
        "formatted_dataset = dataset.map(format_example)"
      ],
      "metadata": {
        "id": "lpmwvU8Lg1W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model.eval()\n",
        "\n",
        "def generate_answer(example):\n",
        "    input_text = example['input_text']\n",
        "\n",
        "    # Tokenize and move inputs to the model's device\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors='pt',\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "    )\n",
        "    input_ids = inputs['input_ids'].to(model.device)\n",
        "    attention_mask = inputs['attention_mask'].to(model.device)\n",
        "\n",
        "    # Generate the model's output\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_new_tokens=15,\n",
        "            do_sample=False,\n",
        "            num_beams=1,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    # Decode the generated tokens\n",
        "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract the answer by removing the input prompt\n",
        "    answer = generated_text[len(input_text):].strip()\n",
        "\n",
        "    # Handle empty outputs\n",
        "    if not answer:\n",
        "        answer = \"No\"\n",
        "        return {'predicted_answer': answer}\n",
        "\n",
        "    # # Keep only the first word (Yes or No)\n",
        "    # answer = answer.split()[0]\n",
        "    # print(answer)\n",
        "\n",
        "    # # Handle unexpected outputs\n",
        "    if 'yes' in answer.lower():\n",
        "        answer = 'Yes'\n",
        "    elif 'no' in answer.lower():\n",
        "        answer = 'No'\n",
        "    else:\n",
        "        answer = 'No'\n",
        "\n",
        "    return {'predicted_answer': answer}\n",
        "\n",
        "\n",
        "# Map the generate_answer function over the validation set\n",
        "predictions = formatted_dataset.map(generate_answer, batched=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9201bdce650c412cbdf35776d3658588",
            "df0ded98c0f244f29d7d3c89a8c24a3b",
            "5d112a12624a4ffaa2b01aee31ef2c65",
            "039c6ad0e769410db2ab65abfbed21b6",
            "ae94d4e9966441abbce82326a2485fb9",
            "eaec53d563f1471c8804b99f010648bd",
            "7c2510a0aa194575963c63572df6e9a7",
            "ee153541b27b47b7b44995f4f1c5fe86",
            "2e57b5f1267f4d07800bff3dcd9e94eb",
            "b527b13061424a16aee1a0cc8adb5ced",
            "4f60072f012b4f8b926dc07d20eb9d1c"
          ]
        },
        "id": "DHmOI7lsg892",
        "outputId": "6f0282bc-3941-4d27-b8d3-07577e5805ee",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3270 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9201bdce650c412cbdf35776d3658588"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_accuracy(predictions):\n",
        "    # Convert the true and predicted answers to lowercase for consistency\n",
        "    true_answers = [answer.lower() for answer in predictions['target_text']]\n",
        "    predicted_answers = [answer.lower() for answer in predictions['predicted_answer']]\n",
        "\n",
        "    # Calculate the number of correct predictions\n",
        "    correct_predictions = sum([\n",
        "        true == pred for true, pred in zip(true_answers, predicted_answers)\n",
        "    ])\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = correct_predictions / len(true_answers)\n",
        "    return accuracy\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = compute_accuracy(predictions)\n",
        "print(f\"Accuracy on the validation set: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "KvEk1vEMhH5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f678e795-77e1-4708-b978-37ea79fd300b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the validation set: 58.38%\n"
          ]
        }
      ]
    }
  ]
}